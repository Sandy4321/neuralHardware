{"name":"Neuralhardware","tagline":"FPGA Based Neural Networks","body":"# Neural Hardware: FPGA-based Neural Networks\r\n## Darrin Willis (dswillis) and Bohan Li (bohanl)\r\n## Summary\r\nWe will be investigating an implementation of Neural Networks into a low-energy FPGA implementation. Neural Networks are a common machine learning algorithm with a high potential for parallelization, which can be exploited by hardware.\r\n\r\n## Background\r\n\r\n## Challenge\r\nDesigning hardware to solve any problem is frequently a more challenging way to develop a computer solution to a problem. The main challenge in this space will be porting a Neural Network solver to the System Verilog hardware description language. The solver will likely utilize some interesting hardware algorithms for pipelining the processes to make maximum use of the hardware. \r\n\r\n## Resources\r\nWe will be utilizing standard tools for live communicating with a host machine, which will include FPGA specific hardware modules and potentially some PC-side libraries for the communication. Along the way, we will likely also make use of some \r\n\r\n## Goals and Deliverables\r\n### Plan to Achieve\r\nA:\r\n - PC-side visualization and analysis of performance live with the FPGA running\r\n - PC-standalone implementation of Neural Network application to compare benchmarks\r\n - (includes all below)\r\n\r\nB:\r\n - In depth analysis of hardware size, speed, power, and complexity\r\n - Alternatively, analysis of why Neural Networks are not a good fit for FPGA implementation\r\n\r\nC:\r\n - Full stack implementation of Neural Network application on FPGA and PC heterogeneous computing environment\r\n\r\n### Hope to Achieve\r\n - Interesting application of neural networks (AI, image processing, etc.)\r\n - Different hardware implementations to compare hardware stacks\r\n\r\n## Platform Choice\r\nFPGAs are the best hardware prototyping tool and are more popular than ever, with the new focus on solving problems on energy sensitive devices. Machine learning has become a mature field, and its algorithms are becoming only more commonplace. It is foreseeable that mobile devices could have an integrated ML chip in them in order to open up a whole new area of applications. This project aims to explore a specific case of these algorithms in the form of Neural Networks.\r\n\r\n## Schedule\r\n###Week of 4/1 to 4/7\r\n - Investigate different available FPGAs and select one\r\n - Investigate PC host environment for FPGAs and what is the best way to interface with FPGA\r\n - Research Neural Networks to gain an initial idea of the hardware algorithm\r\n\r\n###Week of 4/8 to 4/14 (Project Checkpoint)\r\n - Figure out modules for communicating with FPGA and take care of as much boilerplate as possible\r\n - Pick a specific Neural Network application to implement on the FPGA\r\n\r\n###Week of 4/15 to 4/21\r\n - Begin implementing FPGA Neural Network algorithm\r\n - Begin PC-side Neural Network algorithm\r\n - Fix any remaining communication infrastructure\r\n\r\n###Week of 4/22 to 4/28\r\n - Continue developing FPGA algorithm\r\n - Continue developing PC algorithm\r\n - Begin analysis and testing harness for both implementations\r\n\r\n###Week of 4/29 to 5/5\r\n - Finish FPGA algorithm\r\n - Finish PC algorithm\r\n - Create analysis and contrast different hardware implementations\r\n\r\n###Week of 5/6 to 5/11 Parallelism Competition\r\n - Finish up any remaining analysis\r\n - Fix up anything which wasn't yet done","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}